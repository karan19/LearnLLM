# On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?

- **Authors:** Mingmeng Geng, Thierry Poibeau
- **Published:** 2025-10-23T17:59:06Z
- **Source:** http://arxiv.org/abs/2510.20810v1

## Abstract
With the widespread use of large language models (LLMs), many researchers
have turned their attention to detecting text generated by them. However, there
is no consistent or precise definition of their target, namely "LLM-generated
text". Differences in usage scenarios and the diversity of LLMs further
increase the difficulty of detection. What is commonly regarded as the
detecting target usually represents only a subset of the text that LLMs can
potentially produce. Human edits to LLM outputs, together with the subtle
influences that LLMs exert on their users, are blurring the line between
LLM-generated and human-written text. Existing benchmarks and evaluation
approaches do not adequately address the various conditions in real-world
detector applications. Hence, the numerical results of detectors are often
misunderstood, and their significance is diminishing. Therefore, detectors
remain useful under specific conditions, but their results should be
interpreted only as references rather than decisive indicators.

## ELI5
Suppose you build a robot bloodhound to sniff out AI-written paragraphs. The trouble, these authors explain, is that nobody agrees what scent counts as 'AI text' anymore: people tweak chatbot drafts, salvage phrases, or mix machine suggestions with their own prose until the scent is hopelessly diluted. Benchmarks typically ignore such hybrids, evaluating detectors only on pristine, untouched samples, so the resulting metrics lull users into a false sense of certainty. The paper walks through real-world factors—editing, translation, paraphrasing, even humans unconsciously copying AI phrasings—that blur the boundary your bloodhound relies on. Without a crisp definition of the target, detector scores become like weather forecasts without units; they hint at something but cannot be compared or audited. The takeaway is a cautionary tale: treat detection tools as advisory instruments, demand context about what category of text they can truly flag, and push the community to first define the quarry before bragging about capture rates. Until then, 'AI-generated' remains a moving goalpost rather than a binary label.
