# Layer 02 · ML Math & Tooling Core

Bridge classical ML fundamentals with the math that underpins transformers.

## Focus Areas
- Linear algebra refresh: vector spaces, matrix calculus, eigenvalues, low-rank intuition.
- Probability & statistics: Bayesian updates, entropy/cross-entropy, KL divergence, sampling basics.
- Optimization: gradient descent variants, learning-rate schedules, curvature intuition.
- Tooling primers: PyTorch autograd mental model, Hugging Face ecosystem overview, tokenizer training APIs.

## Study Prompts
- Derive cross-entropy loss for next-token prediction and explain each term.
- Compare SGD, Adam, and Lion—when would you reach for each and why?
- Outline how a tokenizer trainer builds merges and how that affects downstream models.

Use this folder to store formula derivations, cheat sheets, and references to courses or papers.
